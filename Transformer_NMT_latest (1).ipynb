{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YVSocT2XnrE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "950efd52-fb28-4cfd-d15c-11a0b6bb70f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "\u001b[1m2638744/2638744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "url=\"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
        "path=tf.keras.utils.get_file(\"spa.zip\",origin=url,extract=True,cache_dir=\"datasets\")\n",
        "data=(Path(path).with_name(\"spa_extracted\")/\"spa-eng\"/\"spa.txt\").read_text(encoding=\"UTF-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OqOyFg18XSKw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "text=data.replace(\"¡\",\"\").replace(\"¿\",\"\")\n",
        "pairs=[line.split(\"\\t\") for line in text.splitlines()]\n",
        "np.random.shuffle(pairs)\n",
        "sentences_en,sentences_esp=zip(*pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AmyB7rvLXUu3"
      },
      "outputs": [],
      "source": [
        "x_train_enc=tf.constant(sentences_en[:100000])\n",
        "x_val_enc=tf.constant(sentences_en[100000:])\n",
        "\n",
        "x_train_dec=tf.constant([f\"startofseq {sen}\" for sen in sentences_esp[:100000]])\n",
        "x_val_dec=tf.constant([f\"startofseq {sen}\" for sen in sentences_esp[100000:]])\n",
        "\n",
        "y_train=[f\"{sen} endofseq\" for sen in sentences_esp[:100000]]\n",
        "y_val=[f\"{sen} endofseq\" for sen in sentences_esp[100000:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Jh4a4hwjXVLH"
      },
      "outputs": [],
      "source": [
        "vocab_size=8000\n",
        "output_len=50\n",
        "enc_vec_layer=tf.keras.layers.TextVectorization(vocab_size,output_sequence_length=output_len)\n",
        "dec_vec_layer=tf.keras.layers.TextVectorization(vocab_size,output_sequence_length=output_len)\n",
        "enc_vec_layer.adapt(sentences_en)\n",
        "dec_vec_layer.adapt([f\"startofseq {s} endofseq\" for s in sentences_esp])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2T0jAJAXbkH"
      },
      "source": [
        "This is the learnable positions method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZG4Ypwh3XcGc"
      },
      "outputs": [],
      "source": [
        "#max_training_len=50\n",
        "#n_dims=128\n",
        "#pos_emb_layer=tf.keras.layers.Embedding(max_training_len,n_dims)\n",
        "#batch_max_len_enc=tf.shape(encoder_embeddings)[1]\n",
        "#encoder_input=encoder_embeddings+pos_emb_layer(tf.range(batch_max_len_enc))\n",
        "#batch_max_len_dec=tf.shape(decoder_embeddings)[1]\n",
        "#decoder_input=decoder_embeddings+pos_emb_layer(tf.range(batch_max_len_dec))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLCXgRkVXeFG"
      },
      "source": [
        "I'll be using the fixed positions method using maths functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Z6nJQHInXhPr"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "    def __init__(self,max_input_len,n_dims,dtype=tf.float32,**kwargs):\n",
        "        super().__init__(dtype=dtype,**kwargs)\n",
        "        assert n_dims%2==0,'n_dims must be even for sin/cos distribution'\n",
        "        p,i=np.meshgrid(np.arange(max_input_len),2*(np.arange(n_dims//2)))\n",
        "        PE=np.empty((1,max_input_len,n_dims))\n",
        "        PE[0,:,::2]=np.sin(p/10000**(i/n_dims)).T\n",
        "        PE[0,:,1::2]=np.cos(p/10000**(i/n_dims)).T\n",
        "        self.embedding_table=tf.constant(PE.astype(self.dtype))\n",
        "        self.supports_masking=True\n",
        "    def call(self,inputs):\n",
        "        inputs=tf.cast(inputs,tf.float32)\n",
        "        batch_max_len=tf.shape(inputs)[1]\n",
        "        return inputs+self.embedding_table[:,:batch_max_len]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ0SvkS0Xt4-"
      },
      "source": [
        "IF MEMORY IS SMALL, IT WILL THROW AN OOM ERROR!!! (100k sentences having 50 tokens/words each, where each token is represented by 128 dims: 100000x50x128 values storing!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OfiqC8kSXuOM"
      },
      "outputs": [],
      "source": [
        "max_training_len=50\n",
        "n_dims=128\n",
        "\n",
        "vec_enc_inputs=enc_vec_layer(x_train_enc)\n",
        "vec_dec_inputs=dec_vec_layer(x_train_dec)\n",
        "vec_y=dec_vec_layer(y_train)\n",
        "\n",
        "vec_enc_inputs_val=enc_vec_layer(x_val_enc)\n",
        "vec_dec_inputs_val=dec_vec_layer(x_val_dec)\n",
        "vec_y_val=dec_vec_layer(y_val)\n",
        "\n",
        "Embedding=tf.keras.layers.Embedding(vocab_size,n_dims,dtype=tf.float32)\n",
        "\n",
        "enc_inputs = tf.keras.Input(shape=(output_len,), dtype=tf.int64)\n",
        "dec_inputs = tf.keras.Input(shape=(output_len,), dtype=tf.int64)\n",
        "\n",
        "enc_emb = Embedding(enc_inputs)\n",
        "dec_emb = Embedding(dec_inputs)\n",
        "\n",
        "pos_enc = PositionalEncoding(512, n_dims)\n",
        "\n",
        "final_encoder_inputs = pos_enc(enc_emb)\n",
        "final_decoder_inputs = pos_enc(dec_emb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yd4PfEsQXwBO"
      },
      "outputs": [],
      "source": [
        "enc_stack_repititions=2\n",
        "Heads=8\n",
        "n_units=512\n",
        "dropout=0.1\n",
        "Z=final_encoder_inputs\n",
        "encoder_pad_mask = tf.keras.layers.Lambda(\n",
        "    lambda x: tf.cast(tf.math.not_equal(x, 0), tf.bool)[:, tf.newaxis, tf.newaxis, :]\n",
        ")(enc_inputs)\n",
        "for _ in range(enc_stack_repititions):\n",
        "    skip=Z\n",
        "    attn_layer=tf.keras.layers.MultiHeadAttention(num_heads=Heads,key_dim=16,dropout=dropout)\n",
        "    Z=attn_layer(Z,value=Z,attention_mask=encoder_pad_mask)\n",
        "    Z=tf.keras.layers.LayerNormalization(epsilon=1e-7)(tf.keras.layers.Add()([Z,skip]))\n",
        "    skip=Z\n",
        "    Z=tf.keras.layers.Dense(n_units,activation=\"relu\")(Z)\n",
        "    Z=tf.keras.layers.Dense(n_dims)(Z)\n",
        "    Z=tf.keras.layers.LayerNormalization(epsilon=1e-7)(tf.keras.layers.Add()([Z,skip]))\n",
        "\n",
        "encoder_output=Z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zI3sBiabXz0G"
      },
      "outputs": [],
      "source": [
        "batch_max_len_dec = tf.keras.layers.Lambda(\n",
        "    lambda x: tf.shape(x)[1]\n",
        ")(final_decoder_inputs)\n",
        "dec_pad_mask = tf.keras.layers.Lambda(\n",
        "    lambda x: tf.cast(tf.math.not_equal(x, 0), tf.bool)[:, tf.newaxis, tf.newaxis, :],\n",
        "    output_shape=lambda s: (s[0], 1, 1, s[1])\n",
        ")(dec_inputs)\n",
        "causal_mask = tf.keras.layers.Lambda(\n",
        "    lambda x: tf.cast(\n",
        "        tf.linalg.band_part(tf.ones((tf.shape(x)[1], tf.shape(x)[1])), -1, 0),\n",
        "        tf.bool\n",
        "    )[tf.newaxis, tf.newaxis, :, :],\n",
        "    output_shape=(1, 1, None, None)\n",
        ")(dec_inputs)\n",
        "combined_mask = tf.keras.layers.Lambda(\n",
        "    lambda inputs: tf.logical_and(inputs[0], inputs[1]),\n",
        "    output_shape=lambda s: s[0]\n",
        ")([dec_pad_mask, causal_mask])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I-xabfmiX1V9"
      },
      "outputs": [],
      "source": [
        "Z=final_decoder_inputs\n",
        "dec_stack_repititions=2\n",
        "for _ in range(dec_stack_repititions):\n",
        "    skip=Z\n",
        "    attn_layer=tf.keras.layers.MultiHeadAttention(dropout=dropout,num_heads=Heads,key_dim=16)\n",
        "    Z=attn_layer(Z,value=Z,attention_mask=combined_mask)\n",
        "    Z=tf.keras.layers.LayerNormalization(epsilon=1e-7)(tf.keras.layers.Add()([Z,skip]))\n",
        "    skip=Z\n",
        "    attn_layer=tf.keras.layers.MultiHeadAttention(dropout=dropout,num_heads=Heads,key_dim=16)\n",
        "    Z=attn_layer(query=Z,key=encoder_output,value=encoder_output,attention_mask=encoder_pad_mask)\n",
        "    Z=tf.keras.layers.LayerNormalization(epsilon=1e-7)(tf.keras.layers.Add()([Z,skip]))\n",
        "    skip=Z\n",
        "    Z=tf.keras.layers.Dense(units=n_units,activation=\"relu\")(Z)\n",
        "    Z=tf.keras.layers.Dense(units=n_dims)(Z)\n",
        "    Z=tf.keras.layers.LayerNormalization(epsilon=1e-7)(tf.keras.layers.Add()([skip,Z]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1uRJweANbek",
        "outputId": "9179250a-8df4-4f51-f6e4-63368d4ebe71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 154ms/step - Accuracy: 0.8598 - loss: 2.1380 - val_Accuracy: 0.9085 - val_loss: 0.5635\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - Accuracy: 0.9159 - loss: 0.5073 - val_Accuracy: 0.9359 - val_loss: 0.3712\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - Accuracy: 0.9406 - loss: 0.3343 - val_Accuracy: 0.9472 - val_loss: 0.2880\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - Accuracy: 0.9518 - loss: 0.2500 - val_Accuracy: 0.9524 - val_loss: 0.2449\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - Accuracy: 0.9581 - loss: 0.2014 - val_Accuracy: 0.9562 - val_loss: 0.2177\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a9d6459d940>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "probas=tf.keras.layers.Dense(vocab_size,activation=\"softmax\")(Z)\n",
        "model=tf.keras.Model(inputs=[enc_inputs,dec_inputs],outputs=probas)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"nadam\",metrics=[\"Accuracy\"])\n",
        "model.fit([vec_enc_inputs,vec_dec_inputs],vec_y,epochs=5,batch_size=256,validation_data=((vec_enc_inputs_val,vec_dec_inputs_val),vec_y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-6w5Ay3yfTmp"
      },
      "outputs": [],
      "source": [
        "def translate(enc_input, model, encoder_vec_layer, decoder_vec_layer,\n",
        "              start_token=\"startofseq\", end_token=\"endofseq\", max_len=50):\n",
        "    start_id = decoder_vec_layer([start_token]).numpy()[0][0]\n",
        "    end_id   = decoder_vec_layer([end_token]).numpy()[0][0]\n",
        "    dec_input=tf.zeros((1,max_len),dtype=tf.int64)\n",
        "    dec_input=tf.tensor_scatter_nd_update(dec_input,[[0,0]],[start_id])\n",
        "    for t in range(1,max_len):\n",
        "        enc_input_vec = encoder_vec_layer([enc_input])\n",
        "        probas = model.predict([enc_input_vec, dec_input], verbose=0)\n",
        "        next_id=tf.argmax(probas[:,t-1,:],axis=-1)[0]\n",
        "        dec_input=tf.tensor_scatter_nd_update(dec_input,[[0,t]],[next_id])\n",
        "        if next_id==end_id:break\n",
        "    vocab = decoder_vec_layer.get_vocabulary()\n",
        "    decoded = [vocab[t] for t in dec_input.numpy()[0]]\n",
        "    sentence = \" \".join(decoded)\n",
        "    return sentence.replace(start_token, \"\").replace(end_token, \"\").strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hkFLJXwIPdiF",
        "outputId": "f27c4240-ee91-46c2-b5ff-e2aa53ce2b28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ésta es la traducción por la [UNK] de la atención'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "translate(\"This is the translation by the magic of attention\",model,enc_vec_layer,dec_vec_layer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"Never give up. The Transformer is finally Working!\",model,enc_vec_layer,dec_vec_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dziLZNrn0f0V",
        "outputId": "1a21a8d8-99b4-4116-a93f-6fe724919fbf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nunca le des la [UNK] es que trabaja'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"Finally! the whole system is working\",model,enc_vec_layer,dec_vec_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AEDUwDd_1BDc",
        "outputId": "e56c9023-1cf3-4979-ec9b-ae65b6ead658"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'finalmente el sistema es malo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28e593da"
      },
      "source": [
        "model.save('transformer_model.keras')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93f82078",
        "outputId": "b73308d1-ee24-458d-82f8-84bf7fd2ad19"
      },
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "source='transformer_model.keras'\n",
        "destination='/content/drive/My Drive/transformer_model.keras'\n",
        "\n",
        "shutil.copy(source,destination)\n",
        "print(f\"Model successfully saved to Google Drive at: {destination}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Model successfully saved to Google Drive at: /content/drive/My Drive/transformer_model.keras\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}